# 计算机网络

## OSI & TCP/IP

- OSI的体系结构（七层）：

    自上而下：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层

- TCP/IP的体系结构（四层）：

    自上而下：应用层、传输层、网际层、网络接口层

- TCP/IP的体系结构（五层）：

    自上而下：应用层、传输层、网络层、数据链路层、物理层

各层的作用：

1. 应用层：通过应用进程间的交互来完成特定的网络应用。应用层协议定义的是应用进程间的通信和交互规则。对于不同的网络应用需要不同的应用层协议。
2. 传输层：负责两台主机进程间的通信提供通用的数据传输服务，应用进程利用该服务传输应用层报文。
3. 网络层：在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换节点，确保数据及时传送。
4. 数据链路层：两台主机之间的数据传输，总是在一段一段的链路上传输的，这就需要专门的链路层协议。在两个相邻节点传送数据时，链路层将网络层交下来的IP数据报封装成帧，在两个相邻节点间的链路传送帧，每一帧包含数据和必要的控制信息（如同步信息，地址信息，差错控制等）。
5. 物理层：实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。

## TCP

TCP如何保证可靠传输：

***TODO***

### ARQ

***TODO***

### 流量控制

***TODO***

### 拥塞控制

***TODO***

### 三次握手

刚开始客户端和服务端均处于CLOSED状态，客户端主动打开连接，服务端被动打开连接，此时服务端处于LISTEN状态。

第一次：客户端给服务端发一个SYN报文，并设置一个序列号。此时客户端进入SYN_SEND状态。

第二次：服务端收到客户端的SYN报文后，以自己的SYN报文作为应答，并指定一个序列号；同时将客户端的序列号+1作为ACK的值，表示自己已收到客户端的SYN报文，此时服务端处于SYN_RCVD状态。

第三次：客户端收到SYN报文后，会发送一个ACK报文，并将服务端报文的序列号+1作为自己的ACK的值，而自己的序列号为第二次握手时服务端ACK报文段的确认号，此时客户端处于ESTABLISHED状态。服务端在收到报文后也进入ESTABLISHED状态，双方建立连接。

**为什么客户端要再发一次确认？**

防止已失效的连接请求报文段突然又传到服务端导致发生错误。

_已失效的连接请求报文段：***TODO***_

### 四次挥手

刚开始双方均处于ESTABLISHED状态，客户端发起关闭请求，

第一次：客户端发送一个FIN报文，报文中指定一个序列号，此时客户端处于FIN_WAIT_1状态。

第二次：服务端收到FIN报文后，会发送ACK报文，确认号指定为客户端FIN报文的序列号+1，同时指定自己的序列号，此时服务端处于CLOSE_WAIT状态。客户端收到来自服务端的确认后进入FIN_WAIT_2状态。

第三次：服务端发出FIN报文，报文指定一个序列号，确认号与第二次挥手时发送给客户端的确认报文一样，此时服务端进入LACK_ACK状态。

第四次：客户端收到服务端的FIN报文后，会发送ACK报文，确认号为服务端FIN报文的序列号+1，自己的序列号指定为第一次挥手时发送给服务端的FIN报文的序列号+1，然后进入TIME_WAIT状态。此时连接仍未释放，须经过时间等待计时器设置的时间2MSL后才进入CLOSED状态。

**为什么要等待2MSL？**

1. 为了保证客户端发送的最后一个ACK报文段到达服务端；
2. 防止已失效的连接请求报文段出现在本连接中。

**为什么要四次？**

***TODO***

### 拆包与粘包

_注：TCP是面向字节流的协议，没有“包”的概念，说“拆包”和“粘包”是为了有助于形象地理解这两种现象。_

- 拆包：如果一次请求发送的数据量比较大，超过了缓冲区大小，TCP会将其拆分为多次发送
- 粘包：如果一次请求发送的数据量比较小，没达到缓冲区大小，TCP会将多个请求合并为同一个进行发送

**解决方法**

- 发送端将每个包都封装成固定的长度
- 发送端在每个包末尾使用固定的分隔符，如`\r\n`，若发生拆包则需要等待多个包发送过来之后找到其中的`\r\n`进行合并
- 将消息分为消息头和消息体，头部保存整个消息的长度，只有读取到足够长度的消息才能算是读到了完整的消息
- 通过自定义协议进行处理

### 短连接与长连接

TCP在进行读写之前，server与client必须提前建立一个连接，建立连接的过程便是三次握手，释放/关闭连接需要四次挥手，这个过程比较消耗网络资源且有时间延迟。

- 短连接：Server与Client建立连接后，读写完成后就关闭连接，下次再要互相发送消息需要重新连接

    短连接实现和管理都比较简单，但每一次读写都建立连接必然会带来大量网络资源的消耗，且建立连接也耗费时间。

- 长连接：Server与Client建立连接后，即使Client与Server完成一次读写，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接

    长连接可以省去较多的TCP建立和关闭的操作，降低对网络资源的依赖，节约时间，对于频繁请求资源的用户来说非常适用长连接。

### 心跳机制

在TCP保持长连接的过程中，可能会出现断网等网络异常情况，异常发生的时候，client和server之间若无交互，双方将无法发现对方已经掉线。为了解决这个问题引入了心跳机制。

Client和Server之间在一定时间内无数据交互时，即处于idle状态时，客户端或服务器就会发送一个特殊的数据包给对方，当接收方收到这个数据报文后，也立即发送一个特殊的数据报文回应发送方，此即一个PING-PONG交互。所以当某一端收到心跳消息后，就知道对方仍然在线，这就确保了TCP连接的有效性。

TCP实际自带长连接选项，本身亦有心跳包机制，也即TCP选项SO_KEEPALIVE。不过TCP层面的长连接灵活性不够，所以一般情况下都是在应用层协议上实现自定义心跳机制。

## UDP

***TODO***

_注：UDP不存在拆包粘包现象，是因为UDP有消息保护边界。_

## HTTP

***TODO***

### 状态码

|状态码|类别|原因短语|
|----|----|----|
|1XX|Informational（信息性）|接收的请求正在处理|
|2XX|Success（成功）|请求正常处理完毕|
|3XX|Redirection（重定向）|需要进行附加操作以完成请求|
|4XX|Client Error（客户端错误）|服务器无法处理请求|
|5XX|Server Error（服务端错误）|服务器处理请求出错|

### HTTP/1.0 & HTTP/1.1

两者区别：

1. 长连接

2. 错误状态响应码

3. 缓存处理

4. 带宽优化及网络连接的使用

### HTTPS

***TODO***

### HTTP长连接和短连接

HTTP/1.0默认使用短连接。

HTTP/1.1默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加上这行代码：

```http
Connection:keep-alive
```

HTTP的短连接和长连接，实质上是TCP的长连接和短连接。

## Session/Cookie

***TODO***

## DNS

***TODO***

## 浏览器输入URL到显示页面的过程

1. 浏览器查找域名对应的IP地址

2. 浏览器向WEB服务器发送一个HTTP请求

3. 服务器处理请求

4. 服务器返回一个HTTP响应

5. 浏览器显示HTML
