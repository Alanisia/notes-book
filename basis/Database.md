# 数据库

## 范式

关系数据库的设计主要是关系模式的设计，关系模式设计的好坏将直接影响到数据库设计的性能，将关系模式规范化是至关重要的。范式消除重复数据减少冗余数据，从而让数据库内的数据更好地组织、让磁盘空间得到更有效利用的一种标准化标准，同时消除潜在的异常（插入异常、更新异常、删除异常）。满足高等级的范式的先决条件是满足低等级范式。

- 第一范式：强调的是列的原子性，即数据库表的每一列都是不可分割的原子数据项；
- 第二范式：在第一范式基础上，消除非主属性对码的部分函数依赖；
- 第三范式：在第二范式基础上，消除非主属性对码的传递函数依赖；
- BC范式：所有属性（包括主属性和非主属性）都依赖于码或者候选键，并不存在传递依赖的情况。

### 优缺点

优点：

- 范式化的数据库更新起来更快；
- 范式化后只有很少的重复数据，只需修改更少的数据；
- 范式化的表更小，可以在内存中执行；
- 很少的冗余数据，在查询时候需要更少的`distinct`或`group by`语句。

缺点：范式化的表在查询时经常需要很多的关联，因为单独一个表内不存在冗余和重复数据，这导致稍微复杂一些的查询语句在查询范式的schema上都可能需要较多次的关联，会增加查询的代价，也可能使一些索引策略无效，因为范式化将列存放在不同的表中，而这些列在一个表中本可属于同一个索引。

_反范式的优缺点：_

- _优点：_

    1. _可以避免关联，因为所有数据几乎都可以在一张表中显示；_
    2. _可以设计有效的索引。_
- _缺点：冗余较多，删除数据会造成有些有用的信息丢失。_

## E-R图

***TODO***

## MySQL

### SQL

SQL具有的功能：数据定义、数据操纵、数据控制。

一条SQL语句在数据库框架中的执行流程：

1. 应用程序把查询SQL语句发送给服务器端执行；
2. 查询缓存，如果查询缓存是打开的，服务器接收到查询请求后，并不会直接去数据库查询，而是在数据库的查询缓存中找是否有相应的查询数据，如果存在，则直接返回给客户端；只有缓存不存在时，才会进行下面的操作；
3. 查询优化处理，生成执行计划，这个阶段主要包括解析SQL、预处理、优化SQL执行计划；
4. MySQL根据相应的执行计划完成整个查询；
5. 将查询结果返回给客户端。

### 存储引擎

- MyISAM

    不支持事务，支持全文索引，不支持外键，只支持表锁，不支持MVCC。

    使用`count()`会直接存储总行数，即对于`select count(*) from table;`如果数据量大会瞬间返回。

- InnoDB

    支持事务，支持全文索引（InnoDB 5.6之后），支持外键，支持表锁和行锁，支持MVCC。

    使用`count()`不会直接存储总行数，即对于`select count(*) from table;`需要一行行扫描。

### 索引

#### 索引分类

- 从数据结构角度

  1. 树索引
  2. [Hash索引](#哈希索引)

- 从物理存储角度

  1. 聚集索引(clustered index)
  2. 非聚集索引(non-clustered index)

- 从逻辑角度

  1. 普通索引
  2. 唯一索引
  3. 主键索引
  4. [联合索引](#联合索引)
  5. 全文索引

#### 索引底层

- 哈希表
- B树
- B+树

InnoDB使用B+树作为索引结构，***TODO***

#### 联合索引

创建联合索引：

```sql
create index indexName on tableName(col1, col2, ..., colN);
```

联合索引可以建立多列（列数>=2，建议不超过3）。

好处：

1. 避免回表

2. 两列单独查返回行多而同时查返回行少的场景，联合索引更高效

#### 聚簇索引&非聚簇索引

**聚簇索引**

将数据存储与索引放到了一块，索引结构的叶子节点保留了数据行，找到索引也就找到了数据。

按照每张表的主键构建一颗B+树，同时叶子节点存放的就是整张表的行记录数据，也将聚集索引的叶子节点称为数据页。这个特性决定了索引组织表中数据也是索引的一部分，每张表只能有一个聚簇索引。

InnoDB通过主键聚集数据，若未定义主键，InnoDB会选择非空的唯一索引代替。若无这样的索引，InnoDB会隐式定义一个主键来作为聚簇索引。InnoDB只聚集在同一个页面中的记录。包含相邻键值的页面可能相距甚远。如果已经设置了主键为聚簇索引，必须先删除主键，然后添加想要的聚簇索引，最后恢复设置主键即可。

聚簇索引优缺点：

- 优点

  1. 数据访问更快，因为聚簇索引将数据和索引保存在同一B+树中
  2. 对于主键的排序查找和范围查找速度非常快

- 缺点

  1. 插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则会出现页分裂，严重影响性能，对于InnoDB表，一般会定义一个自增的ID列作为主键
  2. 更新主键的代价很高，因为将会导致被更新的行移动，对于InnoDB表，一般定义为主键不可更新
  3. 二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据

**非聚簇索引（辅助索引）**

将数据和索引分开存储，索引叶子节点存储的是指向数据行的地址。

InnoDB中在聚簇索引之上创建的索引称为辅助索引，辅助索引访问数据总是二次查找。辅助索引叶子节点存储的不再是行的物理位置，而是主键值，通过辅助索引首先是找到主键值，再通过主键值找到数据行的数据页，再通过数据页中的Page Directory找到数据行。

InnoDB辅助索引的叶子节点并不包含行记录的全部数据，叶子节点除了包含键值外，还包含了相应的行数据的聚簇索引键。辅助索引的存在不影响数据在聚簇索引中的组织，所以一张表能有多个辅助索引。

在MyISAM存储引擎中，默认的索引也是B+树索引，但主索引和辅助索引都是非聚簇索引，亦即索引结构的叶子节点存储的都是一个指向数据行的地址，并且使用辅助索引检索无需访问主键索引。

**何时使用聚簇索引与非聚簇索引**

|动作|聚簇索引|非聚簇索引|
|---|---|---|
|列经常被分组排序|✔️|✔️|
|返回某范围内的数据|✔️||
|一个或极少不同值|||
|小数目的不同值|✔️||
|大数目的不同值||✔️|
|频繁更新的列||✔️|
|外键列|✔️|✔️|
|主键列|✔️|✔️|
|频繁修改索引列||✔️|

#### 哈希索引

哈希索引能以O(1)时间复杂度进行查找，但失去了有序性，无法用于排序与分组，只支持精确查找，无法用于部分查找和范围查找。

InnoDB存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用得非常频繁时，会在B+树索引之上再创建一个哈希索引，这样让B+树索引具有哈希索引的一些优点，比如：快速的哈希查找。

#### 覆盖索引

如果一个索引包含了满足查询语句中字段与条件的数据就叫覆盖索引，覆盖索引具有以下优点：

1. 索引通常远小于数据行的大小，只读取索引能大大减少数据访问量；
2. 一些存储引擎（如MyISAM）的内存中只缓存索引，而数据依赖于操作系统来缓存，因此只访问索引可以不使用系统调用（通常比较费时）；
3. 对于InnoDB引擎，若辅助索引能够覆盖查询，则无需访问主索引。

#### 索引失效

1. 索引列参与表达式计算：

    ```sql
    select `sname` from `stu` where `age` + 10 = 30;
    ```

2. 函数运算：

    ```sql
    select `sname` from `stu` where left(`date`, 4) < 1990;
    ```

3. 模糊查询：

    ```sql
    select * from `manong` where `uname` like '码农%'; -- 走索引
    select * from `manong` where `uname` like '%码农%'; -- 不走索引
    select * from `manong` where `uname` like '_码农%'; -- 不走索引
    ```

    `%`在后面的走索引，除非是要查找的数据被其他占位符占据；`%`在前面的不走索引；

4. 字符串与数字比较：

    ```sql
    create table `a`(`a` char(10));
    explain select * from `a` where `a` = "1"; -- 走索引
    explain select * from `a` where `a` = 1; -- 不走索引
    ```

5. 查询条件有OR，即使其中有条件带索引：

    ```sql
    select * from `dept` where `dname` = 'xxx' or `loc` = 'xx' or `deptno` = 45;
    ```

    换言之，就是要求使用的所有字段，都须建立索引；

6. MySQL内部优化器会对SQL语句进行优化，如果优化器估计使用全表扫描要比使用索引快则不走索引；

7. 正则表达式不走索引。

#### 最左前缀原则

***TODO***

#### 建立索引的原则

1. 选择唯一性索引

    唯一性索引的值是唯一的，可以更快地通过该索引来确定某条记录。

2. 为经常需要排序、分组和联合操作的字段建立索引

    经常需要`order by`、`group by`、`distinct`、`union`等操作的字段，排序操作会浪费很多时间，若为其建立索引可以有效避免排序操作。

3. 为常作为查询条件的字段建立索引

    若常使用某个字段来作为查询条件，那么该字段的查询速度会影响整个表的查询速度，为这样的字段建立索引可以提高整个表的查询速度。

4. 限制索引的数目

    索引不是越多越好，每个索引都会占用磁盘空间，索引越多需要的磁盘空间越大，修改表时对索引的重构和更新很麻烦，越多的索引会使表更新浪费时间。

5. 尽量使用数据量少的索引

    如果索引值很长，那么查询速度会受到影响。

6. 尽量使用前缀来索引

    若索引字段的值很长，最好使用值的前缀来索引，只检索字段前面的若干个字符可以提高检索速度。

7. 删除不再使用或者很少使用的索引

    表中的数据被大量更新，或数据的使用方式被改变后，原有的一些索引可能不再需要，这些索引应将它们删除，从而减少索引对更新操作的影响。

8. 最左前缀匹配原则
9. `=`和`in`可以乱序
10. 尽量选择区分度高的列作为索引

    > 区分度公式为`count(distinct col)/count(*)`，表示字段不重复的比例，比例越大扫描记录数越少，唯一键区分度是1。

11. 索引列不能参与计算
12. 尽量扩展索引而不是新建

### 聚合函数

- `count()`

    **`count(*)`、`count(1)`、`count(column)`的区别**

    - `count(*)`对行的数目进行计算，包含`NULL`，表只有一个字段时最快
    - `count(1)`用法同`count(*)`，如果表无主键则`count(1)`比`count(*)`快
    - `count(column)`对特定的列的值具有的行数进行计算，不包含`NULL`
    - `count(1)`与`count(主键)`只扫描主键，`count(*)`与`count(非主键)`扫描全表
    - 若有主键，则`count(主键, 联合主键)`比`count(*)`快

### 查询优化

- 减少请求的数据量

  - 只返回必要的行
  - 只返回必要的列
  - 缓存重复查询的数据

- 减少服务器端扫描的行数：最有效的方式是使用索引来覆盖查询。

#### SQL优化

1. 避免全表扫描，首先应考虑在`where`及`order by`涉及到的列上建立索引；
2. 尽量避免在`where`子句中使用`!=`或`<>`，否则将使引擎放弃使用索引而进行全表扫描；
3. 尽量避免在`where`子句中对字段进行`null`值判断，否则将使引擎放弃使用索引而进行全表扫描，可以使用默认值`0`来确保没有`null`值；
4. 尽量避免在`where`子句中使用`or`来连接条件，否则将使引擎放弃使用索引而进行全表扫描；
5. 尽量避免在`where`子句中对字段进行表达式操作，否则将使引擎放弃使用索引而进行全表扫描；
6. 尽量避免在`where`子句中对字段进行函数操作，否则将使引擎放弃使用索引而进行全表扫描；
7. 不要在`where`子句中的`=`左边进行函数、算术运算或其他表达式运算，否则将可能无法正确使用索引；
8. 若在`where`子句中使用参数亦会导致全表扫描，因为SQL只在运行期时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时，必须在编译时进行选择；
9. 慎用`in`和`not in`，否则将导致全表扫描；对于连续的数值能用`between`不要用`in`；有时候用`exists`代替`in`是一个好选择；
10. 任何地方都不要使用`select * from`，用具体的字段列表代替`*`，不要返回用不到的字段；
11. 尽可能使用`varchar`/`nvarchar`来代替`char`/`nchar`，首先变长字段存储空间小，可以节省存储空间，其次对于查询来说在一个相对较小的字段内搜索效率显然要高些；
12. 尽量使用数字型字段，若只含数值信息的字段尽量不要设计成字符型，这会降低查询和连接的性能，并会增加存储开销；
13. 在使用索引字段作为条件时，若该索引为复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致；
14. 不要写一些没有意义的查询；
15. 尽量使用表变量来替代临时表，若表变量包含大量数据，注意索引非常有限（只有主键索引）；
16. 避免频繁创建和删除临时表，以减少系统表资源的消耗；
17. 临时表并非不可使用，适当地使用可以使某些例程更有效；
18. 在新建临时表时，若一次性插入数据量很大，那么最好使用`select into`代替`create table`，避免造成大量的log以提高速度；若数据量不大，为了缓和系统表资源，应先`create table`再`insert`；
19. 如果使用到了临时表，在存储过程的最后务必将所有的临时表显示删除，先`truncate table`，然后`drop table`，避免系统表较长时间锁定；
20. 在所有的存储过程和触发器的开始处设置`set nocount on`，在结束时设置`set nocount off`，无需在执行存储过程和触发器的每个语句后向客户端发送`DONE_IN_PROC`消息；
21. 索引不是越多越好，索引固然可以提高相应的`select`的效率，但同时也降低了`insert`及`update`的效率，`insert`和`update`时有可能会重建索引；
22. 应尽可能地避免更新聚集索引数据列，因为聚集索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源；
23. 并不是所有索引都对查询有效，SQL是根据表中的数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引；
24. 尽量避免使用游标，因为游标效率较差，若游标操作的数据超过1万行应考虑改写；
25. 使用基于游标或临时表的方法之前，应先寻找基于集的解决方案来解决问题，基于集的方案通常更有效；
26. 游标并非不可使用，对小数据集使用`FAST_FORWARD`游标通常优于其他逐行处理方法，尤其是必须引用几个表才能获得所需数据时；
27. 尽量避免大事务操作，提高系统并发能力；
28. 尽量避免向客户端返回大数据量，若数据量过大应考虑相应需求是否合理。

#### 慢查询优化

慢查询一般用于记录执行时间超过某个临界值的SQL语句的日志。

相关参数：

- `slow_query_log`：是否开启慢日志查询，1表示开启，0表示关闭
- `slow_query_log_file`：MySQL数据库慢查询日志存储路径
- `long_query_time`：慢查询阈值，当SQL语句查询时间大于阈值，会被记录在日志上
- `log_queries_not_using_indexes`：未使用索引的查询会被记录到慢查询日志中
- `log_output`：日志存储方式，”FILE"表示将日志存入文件，"TABLE"表示将日志存入数据库

优化：

- 分析语句的执行计划，查看SQL语句的索引是否命中
- 优化数据库的结构，将字段很多的表分解成多个表，或者考虑建立中间表
- 优化LIMIT分页

### 事务

逻辑上的一种操作，要么执行，要么不执行。

四大特性（ACID）：

- 原子性（Atomicity）：事务是最小执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用。
- 一致性（Consistency）：执行数据前后，数据保持一致，多个事务对同一数据读取的结果是相同的。
- 隔离性（Isolation）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的。
- 持久性（Durability）：一个事务被提交之后，它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

#### 并发事务带来的问题

- 脏读（Dirty Read）：当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另一个事务也访问了这个数据，然后使用了这个数据。由于这个数据是还没有提交的数据，那么另一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。
- 丢失修改（Lost to Modify）：指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失。
- 不可重复读（Unrepeatable Read）：指在一个事务内多次读同一数据，在这个事务还没有结束时，另一事务也访问该数据，那么在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据不一样，这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。
- 幻读（Phantom Read）：与不可重复读类似，它发生在一个事务读取了几行数据，另一个并发事务插入了一些数据时，在随后的查询中，第一个事务就会发现多了一些原本不存在的记录，就好像发生幻觉一样，因此称为幻读。

#### 事务隔离级别

1. 读取未提交（READ-UNCOMMITTED）：最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、不可重复读和幻读；
2. 读取已提交（READ-COMMITTED）：允许读取并发事务已经提交的数据，可以阻止脏读，但无法阻止幻读和不可重复读；
3. 可重复读（REPEATABLE-READ）：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生；
4. 串行化（SERIALIZABLE）：最高的隔离级别，完全服从ACID，所有的事务依次逐个执行，这样事务之间就能完全不可能产生干扰，可以防止脏读、不可重复读和幻读，但这将严重影响程序的性能。

#### 事务日志

InnoDB事务日志包含redo log和undo log。Redo log是重做日志，提供前滚操作；Undo log是回滚日志，提供回滚操作。

Redo log通常是物理日志，记录的是数据页的物理修改，***TODO***

### 锁机制

- 表级锁：锁定粒度最大的一种锁，对当前操作的整张表加锁。实现简单，资源消耗比较少，加锁快，不会出现死锁。其锁定粒度大，触发锁冲突概率最高，并发度最低。MyISAM和InnoDB引擎都支持表级锁。

- 行级锁：锁定粒度最小的一种锁，只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突，其加锁粒度小，并发度高，但加锁的开销也大，加锁慢，会出现死锁。

    行锁类型：

    - 共享锁（S-Lock）：允许多个事务对于同一数据可以共享一把锁，都能访问到数据，阻止其他事务对于同一数据获取排他锁；
    - 排他锁（X-Lock）：允许事务删除或者更新一行数据，阻止其他事务对于同一数据获取其他锁，包括共享锁和排他锁；`select`语句默认不获取任何锁，所以可读取被其他事务持有排他锁的数据。

    **`for update`**

    在查询时为行加上排他锁，当一个事务的操作未完成时，其他事务可以读取但是不能写入或更新，其典型使用场景是高并发且对于数据的准确性有很高要求。仅适用于InnoDB，且必须开启事务，在`begin`与`commit`之间才能生效。

InnoDB存储引擎的锁算法有三种：

1. Record Lock：单个行记录上的锁
2. Gap Lock：间隙锁，锁定一个范围，不包括记录本身

    > **间隙锁**：在索引记录之间的间隙上的锁。
    >
    > 作用：保证某个间隙内的数据在锁定情况下不会发生任何变化（如MySQL默认隔离级别下的可重复读）。当使用唯一索引来搜索唯一行的语句时不需要间隙锁定，如
    > ```sql
    > select * from t where id = 10 for update;
    > -- 倘若id列没有建立索引或是非唯一索引时，语句会产生间隙锁。
    > ```
    > 若搜索条件里有多个查询条件（即使每个列都有唯一索引）也会产生间隙锁。

3. Next-key Lock：锁定一个范围，包括记录本身

### MVCC

多版本并发控制（Multi-Version Concurrency Control），现代数据库引擎实现中常用的处理读写冲突手段，目的在于提高数据库高并发场景下的吞吐性能。如此一来不同的事务在并发过程中，SELECT操作可以不加锁而是通过MVCC机制读取指定的版本历史记录，并通过一些手段保证读取的记录值符合事务所处的隔离级别，从而解决并发场景下的读写冲突。

InnoDB中MVCC的实现方式：每一行记录都有两个隐藏列：`DATA_TRX_ID`，`DATA_ROLL_PTR`（若无主键还会多一个主键列`DB_ROW_ID`）

***TODO***

### 连接池

> 池化思想：提前保存大量资源，以备不时之需以及重复使用，是一种常用的编程技巧，在请求量大时能明显优化性能，降低系统频繁建立连接的资源开销。其特点是将“昂贵的”、“费时的”的资源维护在一个特定的池中，规定其最小连接数、最大连接数、阻塞队列等配置，方便进行统一管理与复用，通常还会附带一些探活机制、强制回收、监控一类的配套功能。

数据库连接是一种关键的、有限的、昂贵的资源，一个数据库连接对象均对应于一个物理连接，每次操作都打开一个物理连接，使用完都关闭连接，造成系统性能低下。

数据库连接池的解决方案是在应用程序启动时建立足够的数据库连接，并将这些连接组成一个连接池，由应用程序动态地对池中的连接进行申请、使用和释放，对于多个连接池中连接数的并发请求，应该在请求队列中排队等待，并且应用程序可以根据池中连接的使用率，动态增加或减少池中的连接数。

连接池技术尽可能多地重用了消耗内存池资源，大大节省了内存，提高了服务器的服务效率，能够支持更多的客户服务，通过使用连接池，将大大提高程序运行效率，同时可以通过其自身的管理机制来监视数据库连接的数量、使用情况等。

执行一个SQL命令，

- 不使用连接池的步骤：

    1. TCP建立三次握手
    2. MySQL认证的三次握手
    3. 真正的SQL执行
    4. MySQL的关闭
    5. TCP四次挥手关闭

    - 优点：实现简单
    - 缺点：
        1. 网络IO较多
        2. 数据库负载较高
        3. 响应时长较长且QPS较低
        4. 应用频繁地创建连接和关闭连接，导致临时对象变多，GC频繁
        5. 在关闭连接后，会出现大量的TIME_WAIT的TCP状态（在2MSL后关闭）

- 使用连接池的步骤：

    第一次访问时需要建立连接，之后的访问均会复用之前创建的连接，直接执行SQL语句。

    优点：

    1. 减少了网络开销
    2. 系统的性能会有一个实质的提升
    3. 没有了麻烦的TIME_WAIT状态

#### 工作原理

1. 连接池建立

    一般在系统初始化时，连接池会根据系统配置建立，并在池中创建几个连接对象，以便使用时能从连接池中获取，连接池中的连接不能随意创建和关闭，这样避免了连接随意建立和关闭造成的系统开销。

2. 连接池中连接的使用管理

    当客户请求数据库连接时，首先查看连接池中是否有空闲连接，若存在空闲连接，则将连接分配给用户使用；若无空闲连接，则查看当前所开的连接数是否已经达到最大连接数，若未达到则重新创建一个连接给请求的客户；若达到则按设定的最大等待时间进行等待，如果超出最大等待时间，则抛异常给用户。

    当客户释放数据库连接时，先判断该连接的引用次数是否超过了规定值，如果超过就从连接池中删除该连接，否则保留为其他客户服务。

    该策略保证了数据库连接的有效复用，避免频繁建立、释放连接所带来的系统资源开销。

3. 连接池关闭

    当应用程序退出时，关闭连接池中所有的连接，释放连接池相关资源。

#### 主要参数

- 最小连接数：连接池一直保持的数据库连接，如果应用程序对数据库连接的使用量不大，将会有大量的数据库连接资源被浪费；设置该参数可以有两种策略：
    1. 动态：每隔一段时间就对连接池进行检测，如发现连接数量小于最小连接数，则补充相应数量的新连接，以保证连接池正常运转
    2. 静态：发现空闲连接不够时再去检查
- 最大连接数：是连接池能申请的最大连接数，如果数据库连接请求超过次数，后面的数据库连接请求将被加入到等待队列中，会影响之后的数据库操作
- 最大空闲时间：***TODO***
- 获取连接超时时间：***TODO***
- 超时重试连接次数：***TODO***

#### 注意要点

- 并发问题：使连接管理服务具有最大通用性，须考虑多线程环境
- 事务处理：事务具有原子性，当多个线程共用一个连接对象，而且各自都有自己的事务要处理的时候，即使`Connection`类提供了相应的事务支持，可仍无法确定哪个数据库操作对应哪个事务，这是多个线程都在进行事务操作引起的，为此可以使用每一个事务独占一个连接来实现，虽然浪费了连接池资源但可以大大降低事务管理的复杂性
- 连接的分配与释放：合理地分配与释放，可以提高连接的复用度，从而降低建立新连接的开销，同时可以加快用户的访问速度；可以将已经创建的连接都放入一个列表进行管理，每当用户请求一个连接时，系统检查该列表是否存在可以分配的连接，若有就把那个最合适的连接分配予之，否则抛出异常给用户
- 连接池的配置与维护：连接创建过多，系统启动慢但创建后响应速度快，创建过少则系统启动快但创建后响应慢，因此系统可以设置最小连接数与最大连接数等参数来控制连接池中的连接

### 切分

关系型数据库本身容易成为系统瓶颈，单机存储容量、连接数、处理能力都有限，当单表的数据量达到1000W或100G时，由于查询维度较多，即使添加从库、优化索引，做很多操作时性能仍下降严重，此时需考虑进行切分，切分的目的在于减少数据库的负担，缩短查询时间。

数据库分布式核心内容无非就是数据切分（Sharding），以及切分后对数据的定位、整合。数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库操作性能的目的。

根据其切分类型，可以分为垂直（纵向）切分、水平（横向）切分。

- 垂直切分：

    - 垂直分库
    
        根据业务耦合性，将关联度低的不同表存储在不同的数据库，做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。
    - 垂直分表
    
        基于数据库列进行，某个表字段较多，可以新建一张扩展表，将不常使用或字段较大的字段拆分出去到扩展表中，在字段很多的情况下，通过“大表拆小表”，更便于开发与维护，也能避免跨页问题，MySQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销，另外数据库以行为单位将数据加载到内存中，这样表中的字段长度较短且访问频率较高，内存能加载更多的数据，命中率更高，减少磁盘IO，从而提升了数据库性能。

    优点：
    - 解决业务系统层面的耦合，业务清晰
    - 与微服务的治理类似，也能对不同业务的数据进行分级管理、维护、监控、扩展等
    - 高并发场景下，垂直切分一定程度的提升IO、数据库连接数、单机硬件资源的瓶颈

    缺点：
    - 部分表无法`join`，只能通过接口聚合方式解决，提升了开发的复杂度
    - 分布式事务处理复杂
    - 依然存在单表数据量过大的问题（需要水平切分）

- 水平切分

    当一个应用难以再细粒度地垂直切分、或切分后数据量行数巨大，存在单库读写、存储性能瓶颈，这时需要进行水平切分。水平切分分为库内分表和分库分表，根据表内数据内在逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表只包含一部分数据，从而使得单个表的数据量变小，达到分布式效果。

    库内分表只解决了单一表数据量过大的问题，但未将表分布到不同机器的库上，因此对于减轻MySQL数据库的压力来说帮助不是很大，大家仍是竞争同一物理机的CPU、内存、网络IO，最好通过分库分表来解决。

    优点：

    - 不存在单库数据量过大、高并发的性能瓶颈，提升系统稳定性和负载能力
    - 应用端改造较小，不需要拆分业务模块

    缺点：

    - 跨分片的事务一致性难以保证
    - 跨库的`join`关联查询性能较差
    - 数据多次扩展难度和维护量极大

    水平切分后同一张表会出现在多个数据库/表中，每个库/表的内容不同。分片规则：

    - 根据数值范围

        ***TODO***

    - 根据数值取模

        ***TODO***
    
#### 分库分表带来的问题

1. 事务一致性问题

    ***TODO***

2. 跨节点关联查询join问题

    ***TODO***

3. 全局主键避重问题

    分库分表后，不能每个表的id主键都是从1开始累加，需要一个全局唯一的id来支持，生成全局id的方式：

    - UUID：长度过长，不适合作为主键，且无序不可读，查询效率低，较适合用于生成唯一的名字的标识如文件名
    - 自增id：两台数据库分别设置不同步长，生成不重复id的策略来实现高可用，这种方法生成的id有序但需要独立部署数据库实例，成本高且有性能瓶颈
    - 利用redis生成id：性能较好，灵活方便，不依赖于数据库，但引入新组件造成系统更加复杂，可用性降低，编码更加复杂，增加了系统成本
    - _Twitter的snowflake算法_
    - _美团的Leaf分布式id生成系统_

4. 跨节点分页、排序、函数问题

    ***TODO***

5. 数据迁移、扩容问题

    ***TODO***

#### 何时考虑切分

- 能不切分尽量不切分
- 数据量过大，正常运维影响业务访问
- 随着业务发展，需要对某些字段垂直拆分
- 数据量快速增长
- 安全性和可用性

### 读写分离

将数据库分为主从库，一个主库用于写数据，多个从库用于读数据，主从库之间通过某种机制进行数据同步。一个主从同步集群，通常被称为是一个“分组”。

大多数互联网业务往往读多写少，此时数据库的读会首先成为数据库的瓶颈。通过使用分组架构（读写分离架构）能够线性地提升数据库的读性能，消除读写锁冲突从而提升数据库的写性能。

但是数据量大、并发量高、高可用要求高、一致性要求高的场景下，若使用读写分离则需注意这些问题：

- 数据库连接池要进行区分，哪些是读连接池，哪些是写连接池，研发难度增加；
- 为了保证高可用，读连接池要能够实现故障自动转移；
- 主从的一致性问题需要考虑。

仅仅为了解决数据库读瓶颈问题，可以考虑使用缓存，通过缓存减少数据库读的压力，在读写分离和缓存二选一时可优先考虑缓存。缓存使用成本低（比从库少非常多），开发容易（大部分读操作可以先查缓存，查不到再查数据库）。倘若缓存依旧无法解决读瓶颈时，可以考虑读写分离。

### 主从复制

***TODO***

涉及到的线程：

- binlog线程：负责将主服务器上的数据更改写入二进制日志（binary log）中
- SQL线程：负责读取重放日志（relay log）并重放其中的SQL语句
- I/O线程：负责主从服务器上读取二进制日志，并写入从服务器的重放日志中

### 主从同步

**主从同步延迟的原因**

假如一个服务器开放N个连接给服务端，这样会有大并发的更新操作，但是从服务器的里面读取binlog的线程仅有一个，当某个SQL在从服务器上执行的时间稍长或者由于某个SQL要进行锁表就会导致主服务器的SQL大量积压，未被同步到从服务器里，导致主从不一致，即主从延迟。

**解决办法**

所有的SQL必须都要在从服务器里面执行一遍，但是主服务器如果不断有更新的操作源源不断写入，那么一旦有延迟产生，延迟加重的可能性会越来越大。

1. 增加从服务器，分散读的压力，从而降低服务器负载；
2. 主服务器负责更新操作，对安全性要求比从服务器高，有些设置可以修改，如设置`sync_binlog=1`，`innodb_flush_log_at_trx_commit=1`之类的设置，而从服务器则不需要这么高的数据安全，可以设置`sync_binlog=0`或关闭binlog、innodb_flushlog、设置`innodb_flush_log_at_trx_commit=0`来提高SQL执行效率。

## NoSQL

***TODO***

### MongoDB

***TODO***